#!/usr/bin/env python3
"""
Test script for all menu options and edge cases
Tests Options 3 (Help), 4 (Exit), and error handling
"""

import sys
import os

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_import_statements():
    """Test that all required modules can be imported"""
    print("üß™ TESTING IMPORT STATEMENTS")
    print("="*40)
    
    try:
        from core_logic.match_resolver import resolve_match_by_id, resolve_match_ids, get_match_summary
        print("‚úÖ match_resolver imports successful")
        
        from core_logic.data_aggregator import aggregate_all_data, print_aggregation_summary
        print("‚úÖ data_aggregator imports successful")
        
        from core_logic.feature_engine import generate_player_features, batch_generate_features, print_feature_summary, PlayerFeatures
        print("‚úÖ feature_engine imports successful")
        
        from core_logic.team_generator import (
            batch_generate_teams, print_team_summary, print_hybrid_teams_summary, OptimalTeam, 
            get_final_player_score, prepare_players_for_optimization, generate_optimal_teams, generate_hybrid_teams
        )
        print("‚úÖ team_generator imports successful")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Unexpected import error: {e}")
        return False

def test_help_functionality():
    """Test the help functionality"""
    print("\\nüß™ TESTING HELP FUNCTIONALITY")
    print("="*40)
    
    try:
        # Test help content (just check if it runs without error)
        help_content = '''
        DreamTeamAI is an AI-powered Dream11 team predictor that uses
        real cricket data, advanced analytics, and optimization algorithms
        to generate winning fantasy cricket teams using a hybrid strategy.
        '''
        
        print("‚úÖ Help content structure test passed")
        
        # Test new features documentation
        features = [
            "Confidence Scores (1-5 stars)",
            "Ownership Predictions", 
            "Contest Recommendations",
            "Strategic Focus descriptions",
            "Scenario Planning"
        ]
        
        for feature in features:
            print(f"   ‚úÖ {feature}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Help functionality test failed: {e}")
        return False

def test_error_handling():
    """Test error handling for various edge cases"""
    print("\\nüß™ TESTING ERROR HANDLING")
    print("="*40)
    
    try:
        # Test empty match data
        print("üîç Testing empty match data...")
        empty_match = {}
        from core_logic.data_aggregator import aggregate_all_data
        
        result = aggregate_all_data(empty_match)
        if result is None:
            print("‚úÖ Empty match data handled correctly")
        else:
            print("‚ö†Ô∏è  Empty match data returned result (may be fallback)")
        
        # Test invalid match ID format
        print("üîç Testing invalid match ID...")
        try:
            match_id = "invalid_id"
            int(match_id)  # This should fail
            print("‚ùå Invalid match ID not caught")
        except ValueError:
            print("‚úÖ Invalid match ID format handled correctly")
        
        # Test empty player list
        print("üîç Testing empty player list...")
        from core_logic.team_generator import generate_hybrid_teams
        
        empty_players = []
        result = generate_hybrid_teams(empty_players)
        if result == {'Pack-1': [], 'Pack-2': []}:
            print("‚úÖ Empty player list handled correctly")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error handling test failed: {e}")
        return False

def test_data_validation():
    """Test data validation functions"""
    print("\\nüß™ TESTING DATA VALIDATION")
    print("="*40)
    
    try:
        # Test team generation with minimal data
        print("üîç Testing minimal data scenarios...")
        
        # Test confidence score calculation
        from core_logic.team_generator import calculate_team_confidence_score, OptimalTeam
        
        # Create a minimal team for testing
        test_team = OptimalTeam(
            team_id=1,
            players=[],  # Empty players list
            confidence_score=3.0,
            ownership_prediction=50.0,
            contest_recommendation="Both",
            strategic_focus="Balanced"
        )
        
        confidence = calculate_team_confidence_score(test_team)
        print(f"‚úÖ Confidence calculation with empty players: {confidence}")
        
        # Test ownership prediction
        from core_logic.team_generator import calculate_ownership_prediction, PlayerForOptimization
        
        test_player = PlayerForOptimization(
            player_id=1,
            name="Test Player",
            role="batsman",
            team="Team A",
            credits=8.5,
            final_score=50.0
        )
        
        ownership = calculate_ownership_prediction(test_player, [test_player])
        print(f"‚úÖ Ownership prediction: {ownership:.1f}%")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Data validation test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_enhanced_features():
    """Test all enhanced features work correctly"""
    print("\\nüß™ TESTING ENHANCED FEATURES INTEGRATION")
    print("="*40)
    
    try:
        from core_logic.team_generator import (
            determine_contest_recommendation, determine_strategic_focus, 
            generate_scenario_alternatives, OptimalTeam, PlayerForOptimization
        )
        
        # Create test data
        test_players = []
        for i in range(11):
            player = PlayerForOptimization(
                player_id=i,
                name=f"Player {i}",
                role="batsman" if i < 4 else "bowler" if i < 8 else "allrounder" if i < 10 else "wk",
                team="Team A" if i < 6 else "Team B",
                credits=8.0 + i * 0.2,
                final_score=40.0 + i * 5,
                consistency_score=50.0 + i * 2,
                is_captain_candidate=i < 3,
                is_vice_captain_candidate=i < 5,
                ownership_prediction=30.0 + i * 4
            )
            test_players.append(player)
        
        test_team = OptimalTeam(
            team_id=1,
            players=test_players,
            captain=test_players[0],
            vice_captain=test_players[1],
            confidence_score=4.2,
            ownership_prediction=52.5,
            contest_recommendation="Grand",
            strategic_focus="Ceiling"
        )
        
        # Test contest recommendation
        contest_rec = determine_contest_recommendation(test_team)
        print(f"‚úÖ Contest recommendation: {contest_rec}")
        
        # Test strategic focus
        strategic_focus = determine_strategic_focus(test_team, "Form-Based")
        print(f"‚úÖ Strategic focus: {strategic_focus}")
        
        # Test scenario planning
        scenarios = generate_scenario_alternatives(test_team, test_players)
        print(f"‚úÖ Scenario alternatives generated: {len(scenarios)} categories")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Enhanced features integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def run_all_tests():
    """Run all test suites"""
    print("üöÄ RUNNING COMPREHENSIVE TEST SUITE")
    print("="*60)
    
    tests = [
        ("Import Statements", test_import_statements),
        ("Help Functionality", test_help_functionality), 
        ("Error Handling", test_error_handling),
        ("Data Validation", test_data_validation),
        ("Enhanced Features", test_enhanced_features)
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        try:
            print(f"\\n{'='*60}")
            print(f"üß™ RUNNING: {test_name}")
            print(f"{'='*60}")
            
            if test_func():
                print(f"‚úÖ {test_name}: PASSED")
                passed += 1
            else:
                print(f"‚ùå {test_name}: FAILED")
                failed += 1
                
        except Exception as e:
            print(f"‚ùå {test_name}: FAILED with exception: {e}")
            failed += 1
    
    print(f"\\n{'='*60}")
    print(f"üìä TEST RESULTS SUMMARY")
    print(f"{'='*60}")
    print(f"‚úÖ Passed: {passed}")
    print(f"‚ùå Failed: {failed}")
    print(f"üìà Success Rate: {(passed / (passed + failed) * 100):.1f}%")
    
    if failed == 0:
        print(f"\\nüéâ ALL TESTS PASSED! System is ready for production.")
        return True
    else:
        print(f"\\n‚ö†Ô∏è  Some tests failed. Please check the implementation.")
        return False

if __name__ == "__main__":
    success = run_all_tests()
    if success:
        sys.exit(0)
    else:
        sys.exit(1)